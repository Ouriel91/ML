# -*- coding: utf-8 -*-
"""Copy of k_means_clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YktTv4OM0hR0VxUYQEit4Qx8vtiiw7v9

# K-Means Clustering

## Importing the libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""## Importing the dataset"""

dataset = pd.read_csv('Mall_Customers.csv')
# There is no y variable because in clustering we don't have one
# we need to produce one to identifying patterns in data
# so everything should be matrix of features
# except the the id that not relvant to identify patterns
# for the rest of columns age - spending we need to keep only two features
# to plot to 2D plot (the more features we  have the more dimentions in plot and it's harder to visualize
# - 2D plot is nicer)
# so we take the most relavant columns Annual and Spending

col_sub_list  = [3,4]
#print(col_sub_list)

X = dataset.iloc[:, col_sub_list].values

#print(X)
#print(dataset.isnull().sum())

"""## Using the elbow method to find the optimal number of clusters"""

from sklearn.cluster import KMeans

# run KMeans in sort of cluters (1, 2, ..., 10) in for loop
# each time we run KMeans we compute the metrics and clustering
# - Weighted Clusters Sum (of) Squares (WCSS) - means the distance between
# each observation point of the cluster and its central width
# that will be the Y axis in elbow method graph which help us to decide
# the optimal clusters
# (The X axis in elbow method is numbers of clusters)
# we store the WCSS in list

clusters_num = range(1,11) # 10 times, 11 not included
wcss = []

# pick (init) the k-means++ to avoid random initializtion trap
# random state to get same result on each time, 42 is luck number in math :)
# (0,1,42, or any other number serve the same target)

for i in clusters_num:
  m_kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
  m_kmeans.fit(X)
  #print('iter:', i, 'inertia:', m_kmeans.inertia_)
  wcss.append(m_kmeans.inertia_)

#print('full list:',*wcss, sep = "\n")
plt.plot(clusters_num, wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

"""## Training the K-Means model on the dataset"""

# we can see the elbow is 5, 5 numbers of clusters is the optimal clusters number
# that would be the n_clusters
# fit predict, trained and return dependent variable
m_kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42)
y_kmeans = m_kmeans.fit_predict(X)
#print(y_kmeans)
#The actual clusters are still the same, but the labels are randomly assigned,
#so one random state may result new labels
#(the "0" label from one run corresponds to "1" label from the next run and so on).

"""## Visualising the clusters"""

# plt scatter - put x and y coordinate colort and label
# we plot all 5 clusters and centrois
# X coordinate for example X[y_kmeans == 0, 0]
# y_kmeans == 0 - all the rows that clusterd as cluster 0
# ,0 - the first index of matrix, the annual column
# y coordinate same as x coordinate but the column is the spending salary
# s - size of point
# color and label presented as c and label

"""
plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')
plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')
plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')
"""

clusters_num = range(0,5)
colors_points = ['red', 'blue', 'green', 'cyan', 'magenta']
color_centroids = 'yellow'
centroid_label = 'Centroids'
annual_col = 0
spending_col = 1
size_customers_points = 100
size_centroids_points = 300

for i in clusters_num:
  plt.scatter(X[y_kmeans == i, annual_col], X[y_kmeans == i, spending_col], s = size_customers_points, c = colors_points[i], label = 'Cluster '+str(i+1))

plt.scatter(m_kmeans.cluster_centers_[:, annual_col], m_kmeans.cluster_centers_[:, spending_col], s = size_centroids_points, c = color_centroids, label = centroid_label)

plt.title('Clusters of customers')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()